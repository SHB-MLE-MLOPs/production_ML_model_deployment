{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6GMMIwqtZuA"
      },
      "outputs": [],
      "source": [
        "# to handle datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# base or mother object export from sickit-learn\n",
        "# for gettting and setting variables compatible to sickit-learn variables\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "# for fit_transform object compatible to sickit-learn\n",
        "# you need to write fit and transform method in child object contruction\n",
        "from sklearn.base import TransformerMixin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction of the letter and keep it only in the variable Cabin\n",
        "\n",
        "class VariableCabinTransform(BaseEstimator, TransformerMixin):\n",
        "\t# Temporal elapsed time transformer\n",
        "\n",
        "    def __init__(self, variable_list):\n",
        "\n",
        "        if not isinstance(variable_list, list):\n",
        "            raise ValueError('variable_list should be a list')\n",
        "\n",
        "        self.variable_list = variable_list\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # we need this step to fit the sklearn pipeline\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "              raise ValueError('X should be a dataframe')\n",
        "\n",
        "    \t# so that we do not over-write the original dataframe\n",
        "        X = X.copy()\n",
        "\n",
        "        for feature in self.variable_list:\n",
        "            X[feature] = X[feature].str[0]\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "WrmvP17EifXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new features that capture information about presence or abscence of Outliers in data set\n",
        "\n",
        "class OutliersFeatureCreation(BaseEstimator, TransformerMixin):\n",
        "\t# Temporal elapsed time transformer\n",
        "\n",
        "    def __init__(self, outliers_num_vars_list):\n",
        "\n",
        "        if not isinstance(outliers_num_vars_list, list):\n",
        "            raise ValueError('outliers_num_vars should be a list')\n",
        "\n",
        "        self.outliers_num_vars_list = outliers_num_vars_list\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # we need this step to fit the sklearn pipeline\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "              raise ValueError('X should be a dataframe')\n",
        "\n",
        "    \t# so that we do not over-write the original dataframe\n",
        "        X = X.copy()\n",
        "\n",
        "        # capture the outliers and create the new feature\n",
        "        for var in self.outliers_num_vars_list:\n",
        "            # Identify outliers using IQR\n",
        "            Q1 = np.percentile(X[var], 25)\n",
        "            Q3 = np.percentile(X[var], 75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            outliers = (X[var] < lower_bound) | (X[var] > upper_bound)\n",
        "\n",
        "            # add outliers indicator for each columns with outliers data\n",
        "            X[var + '_outliers'] = np.where(outliers, 1, 0)\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "E-AaidozMoRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Temporal elapsed time transformer\n",
        "\n",
        "class TemporalVariableTransformer(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, variables, reference_variable):\n",
        "\n",
        "        if not isinstance(variables, list):\n",
        "            raise ValueError('variables should be a list')\n",
        "\n",
        "        self.variables = variables\n",
        "        self.reference_variable = reference_variable\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # we need this step to fit the sklearn pipeline\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "    \t# so that we do not over-write the original dataframe\n",
        "        X = X.copy()\n",
        "\n",
        "        for feature in self.variables:\n",
        "            X[feature] = X[self.reference_variable] - X[feature]\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "e4VuZol2bvrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for mapping categorical variable like quality, ... : when we have mapping dictionnary\n",
        "\n",
        "class Mapper(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, variables, mappings):\n",
        "\n",
        "        if not isinstance(variables, list):\n",
        "            raise ValueError('variables should be a list')\n",
        "\n",
        "        self.variables = variables\n",
        "        self.mappings = mappings\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # we need the fit statement to accomodate the sklearn pipeline\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for feature in self.variables:\n",
        "            X[feature] = X[feature].map(self.mappings)\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "r0Rs2ZAObvv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for imputation of missing numerical variables (replaced by the mean or mediane or ...)\n",
        "\n",
        "class MeanImputer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Numerical missing value imputer.\"\"\"\n",
        "\n",
        "    def __init__(self, variables):\n",
        "        if not isinstance(variables, list):\n",
        "            raise ValueError('variables should be a list')\n",
        "        self.variables = variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # persist mean values in a dictionary\n",
        "        self.imputer_dict_ = X[self.variables].mean().to_dict()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for feature in self.variables:\n",
        "            X[feature].fillna(self.imputer_dict_[feature],\n",
        "                              inplace=True)\n",
        "        return X"
      ],
      "metadata": {
        "id": "HfNGn0Zob7z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for encoding Rare labels (categorical variable)\n",
        "\n",
        "class RareLabelCategoricalEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Groups infrequent categories into a single string\"\"\"\n",
        "\n",
        "    def __init__(self, variables, tol=0.05):\n",
        "\n",
        "        if not isinstance(variables, list):\n",
        "            raise ValueError('variables should be a list')\n",
        "\n",
        "        self.tol = tol\n",
        "        self.variables = variables\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # persist frequent labels in dictionary\n",
        "        self.encoder_dict_ = {}\n",
        "\n",
        "        for var in self.variables:\n",
        "            # the encoder will learn the most frequent categories\n",
        "            t = pd.Series(X[var].value_counts(normalize=True))\n",
        "            # frequent labels:\n",
        "            self.encoder_dict_[var] = list(t[t >= self.tol].index)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for feature in self.variables:\n",
        "            X[feature] = np.where(\n",
        "                X[feature].isin(self.encoder_dict_[feature]),\n",
        "                                X[feature], \"Rare\")\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "oUOvwjhbb8Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for regression problem\n",
        "# one way for encoding categorical variable to capture monotonic relationship between categorical variables and target\n",
        "\n",
        "# this object will assign discrete values to the strings of the variables,\n",
        "# so that the smaller value corresponds to the category that shows the smaller\n",
        "# mean house sale price\n",
        "\n",
        "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"String to numbers categorical encoder.\"\"\"\n",
        "\n",
        "    def __init__(self, variables):\n",
        "\n",
        "        if not isinstance(variables, list):\n",
        "            raise ValueError('variables should be a list')\n",
        "\n",
        "        self.variables = variables\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        temp = pd.concat([X, y], axis=1)\n",
        "        temp.columns = list(X.columns) + [\"target\"]\n",
        "\n",
        "        # persist transforming dictionary\n",
        "        self.encoder_dict_ = {}\n",
        "\n",
        "        for var in self.variables:\n",
        "            t = temp.groupby([var])[\"target\"].mean().sort_values(ascending=True).index\n",
        "            self.encoder_dict_[var] = {k: i for i, k in enumerate(t, 0)}\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # encode labels\n",
        "        X = X.copy()\n",
        "        for feature in self.variables:\n",
        "            X[feature] = X[feature].map(self.encoder_dict_[feature])\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "A5--4uxjb8RK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}